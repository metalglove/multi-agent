# ============================================
# Runner Configuration (Local Machine)
# ============================================

# Redis connection (connects to docker-compose Redis)
REDIS_URL=redis://127.0.0.1:6379/0

# Event channel name
REDIS_CHANNEL=crewai:events

OPENAI_API_KEY=sk-your-api-key-here
OPENAI_API_BASE=http://localhost:1234/v1

# LLM Configuration
LLM_API_KEY=sk-your-api-key-here
LLM_API_BASE=http://localhost:1234/v1
LLM_MODEL=openai/openai/gpt-oss-20b

# LLM Context Management (for models with limited context windows)
# Set LLM_CONTEXT_WINDOW to your model's maximum context tokens (e.g., 32000)
# Set LLM_MAX_TOKENS to a reasonable output limit (usually 20-25% of context window)
# Examples:
#   - Qwen 4B: context=32000, max_tokens=8000
#   - GPT-4: context=128000, max_tokens=4096
#   - Claude: context=200000, max_tokens=4096
LLM_CONTEXT_WINDOW=128000
LLM_MAX_TOKENS=8000
LLM_TEMPERATURE=0.7

EMBEDDER_MODEL=text-embedding-nomic-embed-text-v1.5
EMBEDDER_DIMS=768

# CrewAI Configuration
CREW_OUTPUT_FOLDER=outputs
# CREWAI_VERBOSE=true

# ============================================
# Docker Services Configuration
# ============================================

# Bridge Service (Docker)
# These are used internally by docker-compose
BRIDGE_PORT=8000
WS_URL=ws://localhost:8000/ws/events
API_BASE_URL=http://localhost:8000

# Frontend Configuration (Docker)
VITE_WS_URL=ws://localhost:8000/ws/events

