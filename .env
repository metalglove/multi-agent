# ============================================
# Runner Configuration (Local Machine)
# ============================================

# Redis connection (connects to docker-compose Redis)
REDIS_URL=redis://127.0.0.1:6379/0

# Event channel name
REDIS_CHANNEL=crewai:events

# LLM Configuration
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_API_BASE=http://localhost:1234/v1
OPENAI_MODEL_NAME=openai/qwen/qwen3-4b-2507

# LLM Context Management (for models with limited context windows)
# Set LLM_CONTEXT_WINDOW to your model's maximum context tokens (e.g., 32000)
# Set LLM_MAX_TOKENS to a reasonable output limit (usually 20-25% of context window)
# Examples:
#   - Qwen 4B: context=32000, max_tokens=8000
#   - GPT-4: context=128000, max_tokens=4096
#   - Claude: context=200000, max_tokens=4096
LLM_CONTEXT_WINDOW=32000
LLM_MAX_TOKENS=8000
LLM_TEMPERATURE=0.7

# CrewAI Configuration
CREW_OUTPUT_FOLDER=outputs
# CREWAI_VERBOSE=true

# ============================================
# Docker Services Configuration
# ============================================

# Bridge Service (Docker)
# These are used internally by docker-compose
BRIDGE_PORT=8000
WS_URL=ws://localhost:8000/ws/events
API_BASE_URL=http://localhost:8000

# Frontend Configuration (Docker)
VITE_WS_URL=ws://localhost:8000/ws/events

